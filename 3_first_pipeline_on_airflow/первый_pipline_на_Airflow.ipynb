{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0I-IEE0ohyt"
      },
      "source": [
        "### Настройка Airflow\n",
        "\n",
        "Для начала вам необходимо выполнить ряд команд чтобы настроить окружение для дальнейшей работы, это позволит первое время не заниматься настройкой среды исполнения, а сразу начать писать код и работать с Airflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0unBvZMyx5H-"
      },
      "source": [
        "# Установка Airflow\n",
        "!pip install apache-airflow==2.1.4\n",
        "\n",
        "# Инициализация базы данных\n",
        "!airflow db init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri_LIxa4z08a"
      },
      "source": [
        "# Создадим необходимые папки\n",
        "!mkdir /root/airflow/dags\n",
        "!touch /root/airflow/dags/dag.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TIpTEhXEoGf"
      },
      "source": [
        "Отройте файл /root/airflow/airflow.cfg перейдите на 634 строку и заменить [smtp] на этот код. Старый код [smtp] удалить.\n",
        "\n",
        "```\n",
        "[smtp]\n",
        "smtp_host = smtp.yandex.ru\n",
        "smtp_starttls = True\n",
        "smtp_ssl = False\n",
        "smtp_user = stepikairflowcourse@yandex.ru\n",
        "smtp_password = 123456aA-\n",
        "smtp_port = 587\n",
        "smtp_mail_from = stepikairflowcourse@yandex.ru\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx1Jfp2O0CBP"
      },
      "source": [
        "# Включим веб-сервер\n",
        "!airflow webserver -p 18273 -D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AicRo890Iyp"
      },
      "source": [
        "# Создадим пользователя Airflow\n",
        "!airflow users create \\\n",
        "          --username admin \\\n",
        "          --firstname admin \\\n",
        "          --lastname admin \\\n",
        "          --role Admin \\\n",
        "          --email admin@example.org \\\n",
        "          -p 12345"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZDvtrO63ntq"
      },
      "source": [
        "Поместите в dag.py следующий код.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "CON = sqlite3.connect('example.db')\n",
        "\n",
        "\n",
        "from airflow import DAG\n",
        "from airflow.utils.dates import days_ago\n",
        "from airflow.operators.email_operator import EmailOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "\n",
        "\n",
        "def extract_data(url, tmp_file, **context) -> pd.DataFrame:\n",
        "    \"\"\" Extract CSV\n",
        "    \"\"\"\n",
        "    pd.read_csv(url).to_csv(tmp_file) # Изменение to_csv\n",
        "\n",
        "\n",
        "def transform_data(group, agreg, tmp_file, tmp_agg_file, **context) -> pd.DataFrame:\n",
        "    \"\"\" Group by data\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(tmp_file) # Изменение read_csv\n",
        "    data.groupby(group).agg(agreg).reset_index().to_csv(tmp_agg_file) # Изменение to_csv\n",
        " \n",
        "\n",
        "def load_data(tmp_file, table_name, conn=CON, **context) -> None:\n",
        "    \"\"\" Load to DB\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(tmp_file)# Изменение read_csv\n",
        "    data[\"insert_time\"] = pd.to_datetime(\"now\")\n",
        "    data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "\n",
        "with DAG(dag_id='dag',\n",
        "         default_args={'owner': 'airflow'},\n",
        "         schedule_interval='@daily',\n",
        "         start_date=days_ago(1)\n",
        "    ) as dag:\n",
        "\n",
        "    extract_data = PythonOperator(\n",
        "        task_id='extract_data',\n",
        "        python_callable=extract_data,\n",
        "        op_kwargs={\n",
        "            'url': 'https://raw.githubusercontent.com/dm-novikov/stepik_airflow_course/main/data/data.csv',\n",
        "            'tmp_file': '/tmp/file.csv'},\n",
        "        dag=dag\n",
        "    )\n",
        "\n",
        "    transform_data = PythonOperator(\n",
        "        task_id='transform_data',\n",
        "        python_callable=transform_data,\n",
        "        dag=dag,\n",
        "        op_kwargs={\n",
        "            'tmp_file': '/tmp/file.csv',\n",
        "            'tmp_agg_file': '/tmp/file_agg.csv',\n",
        "            'group': ['A', 'B', 'C'],\n",
        "            'agreg': {\"D\": sum}}\n",
        "    )\n",
        "\n",
        "    load_data = PythonOperator(\n",
        "        task_id='load_data',\n",
        "        python_callable=load_data,\n",
        "        dag=dag,\n",
        "        op_kwargs={\n",
        "            'tmp_file': '/tmp/file.csv',\n",
        "            'table_name': 'table'\n",
        "        }\n",
        "    )\n",
        "\n",
        "    email_op = EmailOperator(\n",
        "        task_id='send_email',\n",
        "        to=\"stepikairflowcourse@yandex.ru\",\n",
        "        subject=\"Test Email Please Ignore\",\n",
        "        html_content=None,\n",
        "        files=['/tmp/file.csv']\n",
        "    )\n",
        "\n",
        "\n",
        "    extract_data >> transform_data >> [load_data, email_op]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXlUN86A3m1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1242f7a-9c03-4c2d-fde1-73b07bbbb90d"
      },
      "source": [
        "# Запуск шедулера\n",
        "!airflow scheduler -D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7jJGmYR3nGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6566da27-4fef-4df8-fd02-22ab57c55c41"
      },
      "source": [
        "# Последующие команды не имеют отношения к Airflow\n",
        "# Они нужни только для корректной работы веб морды\n",
        "# в среде Google Colab\n",
        "\n",
        "!pip install pyngrok\n",
        "!ngrok authtoken <YOUR TOKEN> # найти его можно https://dashboard.ngrok.com/get-started/setup \n",
        "\n",
        "# Эта команда просто отображет веб морду на другой адрес\n",
        "# Его вы можете найти https://dashboard.ngrok.com/cloud-edge/status\n",
        "# При каждом отключении ссылка будет меняться\n",
        "!nohup ngrok http -log=stdout 18273 > /dev/null &"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sbOlBAm4fUp"
      },
      "source": [
        "После запуска команды выше, перейдите по адресу в ngrok и подождите  пока появится DAG с именем dag"
      ]
    }
  ]
}